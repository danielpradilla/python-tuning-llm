{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e137172-aca5-4480-8fa7-9fc1a36b9796",
   "metadata": {},
   "source": [
    "# Tuning Mistral\n",
    "Works on ml.g5.8xlarge instance with Python 3.10 and PyTorch 2.2.0\n",
    "\n",
    "Based on https://colab.research.google.com/github/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4145eb77-06b2-42d1-a20b-b60bba54054f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 20 08:56:51 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   24C    P0              52W / 300W |      4MiB / 23028MiB |      4%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ba0d89-9d6f-4fe2-8177-c54134e5862e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from bitsandbytes) (1.23.5)\n",
      "Collecting torch\n",
      "  Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers) (3.11.0)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from peft) (5.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting triton==2.2.0\n",
      "  Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.2)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, triton, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, bitsandbytes, accelerate, peft\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-0.29.3 bitsandbytes-0.43.1 fsspec-2024.3.1 huggingface-hub-0.22.2 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 peft-0.10.0 safetensors-0.4.3 sympy-1.12 tokenizers-0.19.1 torch-2.2.2 transformers-4.40.0 triton-2.2.0 typing-extensions-4.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/site-packages (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/site-packages (from huggingface_hub) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface_hub) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface_hub) (3.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from huggingface_hub) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface_hub) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: s3fs in /usr/local/lib/python3.10/site-packages (0.4.2)\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/site-packages (from s3fs) (2024.3.1)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /usr/local/lib/python3.10/site-packages (from s3fs) (1.29.109)\n",
      "Collecting pyarrow>=12.0.0\n",
      "  Using cached pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Collecting pyarrow-hotfix\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from datasets) (23.0)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (1.26.15)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 11.0.0\n",
      "    Uninstalling pyarrow-11.0.0:\n",
      "      Successfully uninstalled pyarrow-11.0.0\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.19.0 frozenlist-1.4.1 multidict-6.0.5 pyarrow-15.0.2 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/site-packages (8.0.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/site-packages (from scipy) (1.23.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (8.12.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (6.22.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.4)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pyzmq>=20 in /usr/local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.0.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Skipping dotenv-python as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping dotenv as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping python-dotenv as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#install stuff\n",
    "!pip uninstall bitsandbytes transformers peft accelerate -y\n",
    "!pip install bitsandbytes transformers peft accelerate\n",
    "!pip install huggingface_hub\n",
    "!pip install s3fs datasets\n",
    "!pip install scipy ipywidgets matplotlib\n",
    "!pip uninstall dotenv-python dotenv python-dotenv -y\n",
    "!pip install python-dotenv\n",
    "!pip install -q wandb -U #weights and biases (optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064a544b-9c3c-4fca-b5b4-203f05ed5b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import timeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0914ae4-72dc-4369-a5c7-d2f6ccdb2b8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb9a1eb-7afb-4358-9ba8-a5a3e04d5317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load globals\n",
    "_ = load_dotenv(find_dotenv(), override=True) # read local .env file\n",
    "WANDB_API = os.getenv('WANDB_API')  # Get weights and biases login\n",
    "HF_TOKEN = os.getenv('HF_TOKEN') #get huggingface login\n",
    "DATASET_PROMPT_FIELD = 'text'\n",
    "BASE_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61afd931-fa26-4666-8b05-554c5204587e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Configure Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149d92b5-ad94-462e-8c1a-a7286fd17b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.14.336, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befeb7f0-a0ce-4242-be81-1bc9867c2ab0",
   "metadata": {},
   "source": [
    "#### Configure Weight and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1653af61-34a3-4cd7-979b-1e92703ba693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielpradilla\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=WANDB_API)\n",
    "\n",
    "wandb_project = \"mistral-tuning\"\n",
    "os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"mistral-tuning-qlora\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e30dd5-121f-4a43-b9d8-a39c6dbbd36f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e41523-ceb7-47f7-85ac-c5103fc73f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m, data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/tuning_training_entries.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m, data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/tuning_validation_entries.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='data/tuning_training_entries.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='data/tuning_validation_entries.jsonl', split='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135571f-441e-4112-8cb4-99c6806043a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.shuffle().select(range(5)).map(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c60250-7936-483f-a27d-d49eaea21149",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdcc2171-de0e-4f26-855c-fc33cfb22089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e396bef0780a497893e95ffbae27ad9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=HF_TOKEN)\n",
    "base_model_id = BASE_MODEL_ID #\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "#base_model_id = \"python-tuning-llm/models/mistral-7b-instruct-v0.1.Q4_0\" #load from local\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d7838-4215-43a1-9f98-3ac50cc7eed4",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Padding in neural networks, particularly in language models like LLaMA, is used to ensure that input sequences are all the same length for batch processing. This uniformity is crucial because it allows the model to perform operations on batches of data efficiently.\n",
    "\n",
    "For fine-tuning a decoder-only model like LLaMA on a chat dataset, you would typically use padding at the end of the sequences. This approach, often called \"post-padding,\" ensures that the beginning of each message (which usually contains the most relevant context) is processed first by the model. Post-padding is generally preferred in natural language processing tasks because it aligns better with how many models process sequential data, reading from the beginning to the end of a sequence.\n",
    "\n",
    "However, For example, input: I love apple [pad] [pad]. The output of the model will contain the input and add additional output information.\n",
    "\n",
    "For example, output: I love apple [pad] [pad],because it is delicious.\n",
    "\n",
    "This would result in [pad] being stuck in the middle of the text. It is very bad for the model to process text. If we use left-padding, the output of this model will be\n",
    "\n",
    "output : [pad] [pad] i love apple,because it is delicious.\n",
    "\n",
    "By padding on the left, the model processes all the padding tokens first, which are typically ignored or masked out in the computational process, and then processes the meaningful input. This ensures that the semantic flow of the text (i.e., the actual content) is uninterrupted and continuous, leading to more coherent outputs.\n",
    "\n",
    "Most neural network architectures, including LLMs, are sensitive to the sequence's start since they are trained to weigh initial inputs more significantly. Left-padding ensures that the meaningful part of the input is aligned closer to the point of decision-making in the model architecture, which in this case is the generation of the continuation of the text.\n",
    "\n",
    "Source: [https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa]\n",
    "\n",
    "For model_max_length, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1d4381-4d2a-4469-a55d-737d17c81450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_prompt(prompt):\n",
    "    return tokenizer(prompt[DATASET_PROMPT_FIELD])\n",
    "\n",
    "#reformat the prompt and tokenize each sample\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "584afccf-9c8c-4c8e-990f-3dcf847cb8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 2678\n",
      "min: 30\n",
      "max: 41009\n",
      "outlier limit: 1921.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/2767001568.py:22: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode_result = mode(capped_lengths)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#inspect distribution of lengths to figure out the max_length of the input tensors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(f\"samples: {len(lengths)}\")\n",
    "    print(f\"min: {min(lengths)}\")\n",
    "    print(f\"max: {max(lengths)}\")\n",
    "    \n",
    "    # Calculate the 3IQR for utliers    \n",
    "    outlier_limit = np.percentile(lengths, 75) + 3 * (np.percentile(lengths, 75) - np.percentile(lengths, 25))\n",
    "    print(f\"outlier limit: {outlier_limit}\")\n",
    "    capped_lengths = [min(length, outlier_limit) for length in lengths]\n",
    "\n",
    "    # Calculate mode and median\n",
    "    median_length = np.median(capped_lengths)\n",
    "    try:\n",
    "        mode_result = mode(capped_lengths)\n",
    "        mode_length = mode_result.mode[0] if mode_result.count[0] > 0 else None\n",
    "    except IndexError:\n",
    "        mode_length = None\n",
    "\n",
    "    # Calculate 95% and 99% percentiles\n",
    "    percentile_75 = np.percentile(lengths, 75)\n",
    "    percentile_95 = np.percentile(lengths, 95)\n",
    "    percentile_97 = np.percentile(lengths, 97)\n",
    "    \n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(capped_lengths, bins=20, alpha=0.7, color='blue')\n",
    "    \n",
    "    #reference lines\n",
    "    plt.axvline(median_length, color='red', linestyle='dashed', linewidth=2, label=f'Median: {median_length}')\n",
    "    if mode_length is not None:\n",
    "        plt.axvline(mode_length, color='green', linestyle='dashed', linewidth=2, label=f'Mode: {mode_length}')\n",
    "    plt.axvline(percentile_75, color='magenta', linestyle='dashed', linewidth=2, label=f'75th Percentile: {percentile_75:.2f}')\n",
    "    plt.axvline(percentile_95, color='orange', linestyle='dashed', linewidth=2, label=f'95th Percentile: {percentile_95:.2f}')\n",
    "    plt.axvline(percentile_97, color='purple', linestyle='dashed', linewidth=2, label=f'97th Percentile: {percentile_97:.2f}')\n",
    "        \n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2b7fc-edd7-42e2-bf61-2195b9b3d1b6",
   "metadata": {},
   "source": [
    "Low max_length: loss of contextual information, only the initial part of long texts is retained. Truncation bias: underrepresentation of longer documents. Reduced model performance if it's too low\n",
    "\n",
    "Large max_length: hitting model constraints on length, impact on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1c88d7-4fcd-4558-95e3-80276aa0066b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#re-tokenize now that i know the lengths\n",
    "max_length = 542\n",
    "def tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        text = prompt[DATASET_PROMPT_FIELD],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "tokenized_train_dataset2 = train_dataset.map(tokenize_prompt2)\n",
    "tokenized_val_dataset2 = eval_dataset.map(tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df436a69-6292-4f0e-a254-a0446adf44ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 733, 16289, 28793, 28749, 11666, 1849, 7142, 1540, 340, 890, 3756, 1959, 8103, 1921, 1061, 13447, 23396, 28705, 28770, 28770, 11048, 28792, 28748, 16289, 28793, 1618, 22441, 28324, 28709, 340, 3118, 543, 289, 434, 3428, 363, 2374, 488, 515, 936, 520, 389, 23199, 28725, 4777, 21186, 519, 3594, 3118, 2144, 415, 334, 482, 14546, 497, 28706, 5799, 1452, 379, 8854, 656, 10704, 337, 261, 5388, 497, 269, 639, 936, 381, 2995, 5326, 340, 365, 28733, 28782, 28750, 28713, 28723, 13, 13, 5173, 9928, 28725, 2914, 412, 8534, 383, 1711, 28725, 11176, 305, 2004, 28709, 340, 319, 3583, 385, 28725, 1037, 521, 20962, 2646, 1201, 21010, 1452, 28725, 708, 12811, 1452, 28723, 10677, 3118, 390, 8322, 481, 26756, 298, 574, 2187, 11402, 28747, 13, 28792, 11203, 28747, 2872, 1508, 2849, 28723, 450, 783, 28734, 28734, 28740, 28723, 675, 28748, 9660, 28748, 10323, 28729, 2298, 28748, 20246, 28723, 1447, 28770, 28793, 13, 13, 1976, 28742, 267, 272, 2746, 13, 6087, 613, 28742, 333, 750, 4999, 288, 302, 13, 1548, 1854, 315, 403, 264, 1628, 2746, 13, 13, 3261, 20540, 340, 21979, 1150, 5689, 28725, 315, 28742, 28719, 459, 9575, 3453, 574, 18173, 910, 298, 9773, 395, 368, 1037, 521, 957, 269, 8284, 28709, 340, 467, 10124, 293, 283, 543, 20427, 2126, 340, 1515, 19134, 1079, 385, 264, 1448, 415, 662, 311, 10774, 337, 526, 463, 2507, 639, 22667, 23209, 1637, 28708, 11997, 882, 13680, 28725, 26899, 340, 11779, 28737, 27658, 286, 264, 10850, 22334, 340, 14294, 28724, 24150, 28723, 13, 13, 28792, 11203, 28747, 2872, 1508, 2849, 28723, 450, 783, 28734, 28734, 28740, 28723, 675, 28748, 9660, 28748, 10323, 28729, 2298, 28748, 424, 595, 28723, 1447, 28770, 28793, 13, 13, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1072b2e3-6473-4982-b7e2-c5700131af50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 2678\n",
      "min: 542\n",
      "max: 542\n",
      "outlier limit: 542.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/2767001568.py:22: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode_result = mode(capped_lengths)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset2, tokenized_val_dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc105ea-1d60-4a5c-9b48-e20c878f681c",
   "metadata": {},
   "source": [
    "## Test model out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65b552c5-c3cf-44fa-9616-6d36f824d802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\"<s>[INST]Given the following biometric data, score the users' health, from 0-100.\n",
    "\n",
    "### Biometric Data:\n",
    "Temperature=98.2,\n",
    "Sex=F,\n",
    "Age=29,\n",
    "Height=69 inches,\n",
    "Weight=160 lbs,\n",
    "V02_Max=55,\n",
    "HRV=55\n",
    "[/INST]\n",
    "### Health Score</s>:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1062d6e5-18b9-4797-a0c3-f483bc23d947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_inst_text(record):\n",
    "    pattern = r\"\\[INST\\](.*?)\\[/INST\\]\"\n",
    "    match = re.search(pattern, record['text'])\n",
    "    return {'inst_text': match.group(1) if match else None}\n",
    "\n",
    "# Shuffle the dataset, select one record, and apply the map function\n",
    "sample_record = train_dataset.shuffle(seed=42).select([0]).map(extract_inst_text)\n",
    "\n",
    "# Access the extracted text\n",
    "eval_prompt = sample_record['inst_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a10605-c285-4246-a402-611b00bdc599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd93f4-03df-4f83-97a5-a19bff39ff9d",
   "metadata": {},
   "source": [
    "## Configure Lora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94a26629-17ff-4268-a7ae-4ac83bc58101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a25bdaf-9cbe-446d-a73d-585fbeddb78e",
   "metadata": {},
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`, and `lm_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "394a4226-2652-4920-94eb-5b819f0c8cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62252954-5237-46b9-93f0-9d5a176bbb69",
   "metadata": {},
   "source": [
    "The LoRA (Low-Rank Adaptation) configuration involves adjusting parameters specifically designed to fine-tune large pre-trained models in a computationally efficient manner. Let's break down the key components and the impact of your chosen settings:\n",
    "\n",
    "\n",
    "Rank (r):\n",
    "Definition: In the context of LoRA, the rank (r) refers to the rank of the low-rank matrices that are introduced to adapt the pre-existing weight matrices of a neural network. This concept is derived from matrix factorization, where a matrix is approximated by two smaller matrices whose product provides a good approximation of the original one.\n",
    "\n",
    "Impact: The rank determines the number of trainable parameters added during the fine-tuning process. A higher rank increases the expressivity of the adaptation, allowing the model to more significantly adjust its pre-trained behaviors. However, a higher rank also increases the computational requirements since more parameters mean more calculations during both training and inference.\n",
    "Trade-off: Choosing a lower rank, such as r=32 instead of the originally used r=64, reduces the computational load and the number of parameters, which can be beneficial in resource-constrained environments or when faster adaptation is needed.\n",
    "\n",
    "\n",
    "Scaling Factor (alpha):\n",
    "Definition: The scaling factor alpha is used to scale the contributions of the low-rank matrices. In the adaptation process, the original weights of the model are modified by adding the product of the low-rank matrices, which is scaled by alpha/r.\n",
    "Impact: The choice of alpha affects how much influence the low-rank updates have on the original model weights. A higher alpha gives greater emphasis to the adjustments made by the LoRA adaptation, potentially leading to more pronounced changes in model behavior based on the fine-tuning data.\n",
    "Trade-off: By choosing a higher alpha (64 versus the originally used 16), we are emphasizing the fine-tuning updates more heavily. This can be particularly useful when the fine-tuning data is very different from the data the model was initially trained on, or when specific behaviors need to be significantly adjusted.\n",
    "\n",
    "Practical Implications\n",
    "Generalization vs. Specialization: The original settings (r=64, lora_alpha=16) suggested in the QLoRA paper are likely aimed at providing a balanced approach that generalizes well across various tasks without overly deviating from the model's pre-trained base. The choice of r=32 and lora_alpha=64 shifts this balance towards greater specialization based on the fine-tuning data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31694bd4-1983-4efc-be19-955beafd0fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "    \n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaabb19a-200d-418b-b94c-62e7c71314db",
   "metadata": {},
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a9e784d-eb35-4b95-a2e8-1cd8657db366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c626cdc-4764-406e-a244-fe543462c530",
   "metadata": {},
   "source": [
    "## Run training\n",
    "\n",
    "The evolution of the training can be followed in wandb.ai, each time a checkpoint is saved it is represented in the run over there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af15f80-0df4-4a45-bf55-8593f31d1425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ae8b385-feb2-4e74-8a24-708ec731ada7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eecc05e8-a285-4392-9326-24e067b2f173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.14.336, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/python-tuning-llm/tuning-mistral-qlora/wandb/run-20240420_070417-vn85eby9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielpradilla/mistral-qlora-finetune/runs/vn85eby9' target=\"_blank\">mistral-journal-finetune-2024-04-20-07-04</a></strong> to <a href='https://wandb.ai/danielpradilla/mistral-qlora-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielpradilla/mistral-qlora-finetune' target=\"_blank\">https://wandb.ai/danielpradilla/mistral-qlora-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielpradilla/mistral-qlora-finetune/runs/vn85eby9' target=\"_blank\">https://wandb.ai/danielpradilla/mistral-qlora-finetune/runs/vn85eby9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='247' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [247/500 59:20 < 1:01:17, 0.07 it/s, Epoch 0.11/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.269200</td>\n",
       "      <td>2.707937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.711300</td>\n",
       "      <td>2.531080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.552700</td>\n",
       "      <td>2.401214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.252100</td>\n",
       "      <td>2.331468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.273600</td>\n",
       "      <td>2.295082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.241500</td>\n",
       "      <td>2.280778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.312300</td>\n",
       "      <td>2.263667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.281100</td>\n",
       "      <td>2.242250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2.297900</td>\n",
       "      <td>2.197683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.321800</td>\n",
       "      <td>2.171704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>2.356400</td>\n",
       "      <td>2.145884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.198600</td>\n",
       "      <td>2.129740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>2.273100</td>\n",
       "      <td>2.116914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.418900</td>\n",
       "      <td>2.101531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.281400</td>\n",
       "      <td>2.087453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.777700</td>\n",
       "      <td>2.061471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.27 GiB. GPU 0 has a total capacity of 15.77 GiB of which 887.62 MiB is free. Process 9851 has 14.90 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 52.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimport transformers\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom datetime import datetime\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mproject = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjournal-finetune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mbase_model_name = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistral\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun_name = base_model_name + \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m + project\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43moutput_dir = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m + run_name\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mtrainer = transformers.Trainer(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    model=model,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    train_dataset=tokenized_train_dataset,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    eval_dataset=tokenized_val_dataset,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    args=transformers.TrainingArguments(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        output_dir=output_dir,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        warmup_steps=2,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        #auto_find_batch_size=True,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        per_device_train_batch_size=1,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        per_device_eval_batch_size=1,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        gradient_accumulation_steps=1,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        eval_accumulation_steps=1,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        gradient_checkpointing=True,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        max_steps=500,               #number of training steps\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        learning_rate=2.5e-5,        # Want a small lr for finetuning\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        #bf16=True,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        fp16=True,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        #optim=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaged_adamw_8bit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        optim=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madamw_bnb_8bit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        logging_steps=15,              # When to start reporting loss\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        logging_dir=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,        # Directory for storing logs\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        save_strategy=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,       # Save the model checkpoint every logging step\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        save_steps=15,                # Save checkpoints every 25 steps\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        evaluation_strategy=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, # Evaluate the model every logging step\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        eval_steps=15,               # Evaluate and save checkpoints every 25 steps\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        do_eval=True,                # Perform evaluation at the end of training\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        report_to=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,           # Comment this out if you don\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mt want to use weights & baises\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        run_name=f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{run_name}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mdatetime.now().strftime(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)}\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,          # Name of the W&B run (optional),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        gradient_checkpointing_kwargs=\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_reentrant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: True}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmodel.config.use_cache = False  # silence the warnings. Please re-enable for inference!\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mtrainer.train()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2475\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2474\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2475\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2477\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/magics/execution.py:1170\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1169\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1170\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1172\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/magics/execution.py:158\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    156\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:43\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2209\u001b[0m ):\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/trainer.py:3138\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3138\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3141\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/trainer.py:3161\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3160\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/accelerate/utils/operations.py:825\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/accelerate/utils/operations.py:813\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/peft/peft_model.py:1129\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1128\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:161\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1158\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1155\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1158\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1171\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1004\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdpa\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;66;03m# output_attentions=True can not be supported when using SDPA, and we fall back on\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# the manual implementation that requires a 4D causal mask in all cases.\u001b[39;00m\n\u001b[0;32m-> 1004\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_causal_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m     \u001b[38;5;66;03m# 4d mask is passed through the layers\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_causal_attention_mask(\n\u001b[1;32m   1014\u001b[0m         attention_mask,\n\u001b[1;32m   1015\u001b[0m         (batch_size, seq_length),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         sliding_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msliding_window,\n\u001b[1;32m   1019\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:389\u001b[0m, in \u001b[0;36m_prepare_4d_causal_attention_mask_for_sdpa\u001b[0;34m(attention_mask, input_shape, inputs_embeds, past_key_values_length, sliding_window)\u001b[0m\n\u001b[1;32m    385\u001b[0m     expanded_4d_mask \u001b[38;5;241m=\u001b[39m attn_mask_converter\u001b[38;5;241m.\u001b[39mto_causal_4d(\n\u001b[1;32m    386\u001b[0m         input_shape[\u001b[38;5;241m0\u001b[39m], input_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], key_value_length, dtype\u001b[38;5;241m=\u001b[39minputs_embeds\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39minputs_embeds\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m     expanded_4d_mask \u001b[38;5;241m=\u001b[39m \u001b[43mattn_mask_converter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_4d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_value_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# Attend to all tokens in masked rows from the causal_mask, for example the relevant first rows when\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# using left padding. This is required by F.scaled_dot_product_attention memory-efficient attention path.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# Details: https://github.com/pytorch/pytorch/issues/110213\u001b[39;00m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing \u001b[38;5;129;01mand\u001b[39;00m expanded_4d_mask\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:132\u001b[0m, in \u001b[0;36mAttentionMaskConverter.to_4d\u001b[0;34m(self, attention_mask_2d, query_length, dtype, key_value_length)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSliding window is currently only implemented for causal masking\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m expanded_attn_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_expand_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    133\u001b[0m     attention_mask_2d\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m causal_4d_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     expanded_attn_mask \u001b[38;5;241m=\u001b[39m causal_4d_mask\u001b[38;5;241m.\u001b[39mmasked_fill(expanded_attn_mask\u001b[38;5;241m.\u001b[39mbool(), torch\u001b[38;5;241m.\u001b[39mfinfo(dtype)\u001b[38;5;241m.\u001b[39mmin)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:184\u001b[0m, in \u001b[0;36mAttentionMaskConverter._expand_mask\u001b[0;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[1;32m    180\u001b[0m tgt_len \u001b[38;5;241m=\u001b[39m tgt_len \u001b[38;5;28;01mif\u001b[39;00m tgt_len \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m src_len\n\u001b[1;32m    182\u001b[0m expanded_mask \u001b[38;5;241m=\u001b[39m mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m1\u001b[39m, tgt_len, src_len)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[0;32m--> 184\u001b[0m inverted_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexpanded_mask\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inverted_mask\u001b[38;5;241m.\u001b[39mmasked_fill(inverted_mask\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool), torch\u001b[38;5;241m.\u001b[39mfinfo(dtype)\u001b[38;5;241m.\u001b[39mmin)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor.py:941\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VariableFunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.27 GiB. GPU 0 has a total capacity of 15.77 GiB of which 887.62 MiB is free. Process 9851 has 14.90 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 52.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"tuning-qlora\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        #auto_find_batch_size=True,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        eval_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,               #number of training steps\n",
    "        learning_rate=2.5e-5,        # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        #fp16=True,\n",
    "        #optim=\"paged_adamw_8bit\",\n",
    "        optim=\"adamw_bnb_8bit\",\n",
    "        logging_steps=15,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=15,                # Save checkpoints every 25 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=15,               # Evaluate and save checkpoints every 25 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",          # Name of the W&B run (optional),\n",
    "        gradient_checkpointing_kwargs={\"use_reentrant\": True}\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94ce3e-7b4e-4349-b1e0-29ac4cff5942",
   "metadata": {},
   "source": [
    "## Try the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1941cf9f-4033-48bc-8a2e-9e026335ea30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a6d9ac60b7474ea73bffa62f04f743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = BASE_MODEL_ID\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf0eb0-a39e-48d0-9556-2831c98e686f",
   "metadata": {},
   "source": [
    "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93f4cc7b-3ffc-4756-bab4-2fc0c3c5510b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-tuning-qlora/checkpoint-240\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6c63e-78d3-4be8-a15a-f4b2c56c5180",
   "metadata": {},
   "source": [
    "try the same input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1dc3402-c122-4f36-b23b-1773afb4cef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d8017fcaf644cc903a0f6512aecf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shuffle the dataset, select one record, and apply the map function\n",
    "sample_record = train_dataset.shuffle().select([0]).map(extract_inst_text)\n",
    "\n",
    "# Access the extracted text\n",
    "eval_prompt = sample_record['inst_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e853c9-4992-4e3b-b4cd-3eede18207fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=1000, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d41991-e1be-48c8-b2bb-b13076eddcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g5.xlarge",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
